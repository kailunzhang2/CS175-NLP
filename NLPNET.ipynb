{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed081e9-4cbe-4cb2-98ba-8c86d8161923",
   "metadata": {},
   "source": [
    "# CS175 project: Generative Conversational Chatbot by nlpnet\n",
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1a31a6-fc65-4244-a9aa-4f02a9bb0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2cd8a2-42ac-4700-9ebb-2db01847099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0b35c7-cf02-4dd8-8972-b48d27731d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device check: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device check: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed4973-1b3c-4cce-9f3e-a67a9432947f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load & Preprocess Datasets\n",
    "    Reference:\n",
    "        https://pytorch.org/tutorials/beginner/chatbot_tutorial.html\n",
    "\n",
    "### The Cornell Movie-Dialogs Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5551ab-19b9-4c21-afce-3f4c42ba3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file to create lines and conversations\n",
    "def loadLinesAndConversations(fileName):\n",
    "    lines = {}\n",
    "    conversations = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            lineJson = json.loads(line)\n",
    "            # Extract fields for line object\n",
    "            lineObj = {}\n",
    "            lineObj[\"lineID\"] = lineJson[\"id\"]\n",
    "            lineObj[\"characterID\"] = lineJson[\"speaker\"]\n",
    "            lineObj[\"text\"] = lineJson[\"text\"]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "\n",
    "            # Extract fields for conversation object\n",
    "            if lineJson[\"conversation_id\"] not in conversations:\n",
    "                convObj = {}\n",
    "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
    "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
    "                convObj[\"lines\"] = [lineObj]\n",
    "            else:\n",
    "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
    "                convObj[\"lines\"].insert(0, lineObj)\n",
    "            conversations[convObj[\"conversationID\"]] = convObj\n",
    "\n",
    "    return lines, conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations.values():\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28080157-db78-4ab7-885a-edd8fd7a4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus into lines and conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "corpus = 'cornell-movie-corpus'\n",
    "corpus_name = corpus\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict and conversations dict\n",
    "lines = {}\n",
    "conversations = {}\n",
    "# Load lines and conversations\n",
    "print(\"\\nProcessing corpus into lines and conversations...\")\n",
    "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"))\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81214e23-6c9e-402b-944d-6d93b4ca9d35",
   "metadata": {},
   "source": [
    "## Load and trim data\n",
    "    Reference:\n",
    "        https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cd4518-55ec-4c1d-9744-5af5cefff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5feac07c-d152-48ca-8da0-b58467b02d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 168840 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 37402\n",
      "Amount of pairs: 168840\n",
      "\n",
      "pairs:\n",
      "['they do to !', 'they do not !']\n",
      "['she okay ?', 'i hope so .']\n",
      "['wow', 'let s go .']\n",
      "['i m kidding . you know how sometimes you just become this persona ? and you don t know how to quit ?', 'no']\n",
      "['no', 'okay you re gonna need to learn how to lie .']\n",
      "['i figured you d get to the good stuff eventually .', 'what good stuff ?']\n",
      "['what good stuff ?', 'the real you .']\n",
      "['the real you .', 'like my fear of wearing pastels ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what crap ?', 'me . this endless . . .blonde babble . i m like boring myself .']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 25  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print('Amount of pairs:', len(pairs))\n",
    "\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae743a-80fb-4260-a133-8e73905358f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Microsoft Research WikiQA Corpus Preprocessing & Merging with the list of pairs\n",
    "    Codes written by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4a22c8-6f96-476d-b81d-2fc5210c9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
       "      <td>As such, African immigrants are to be distingu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>A glacier cave is a cave formed within the ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how a water pump works</td>\n",
       "      <td>Pumps operate by some mechanism (typically rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how big is bmc software in houston, tx</td>\n",
       "      <td>Employing over 6,000, BMC is often credited wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how big is bmc software in houston, tx</td>\n",
       "      <td>For 2011, the company recorded an annual reven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>This tablespoon has a capacity of about 15 mL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>In the USA one tablespoon (measurement unit) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>In Australia one tablespoon (measurement unit)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how much are the harry potter movies worth</td>\n",
       "      <td>The series also originated much tie-in merchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how a rocket engine works</td>\n",
       "      <td>A rocket engine, or simply \"rocket\", is a jet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Question  \\\n",
       "0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
       "1                    how are glacier caves formed?   \n",
       "2                           how a water pump works   \n",
       "3           how big is bmc software in houston, tx   \n",
       "4           how big is bmc software in houston, tx   \n",
       "5                how much is 1 tablespoon of water   \n",
       "6                how much is 1 tablespoon of water   \n",
       "7                how much is 1 tablespoon of water   \n",
       "8       how much are the harry potter movies worth   \n",
       "9                        how a rocket engine works   \n",
       "\n",
       "                                            Sentence  \n",
       "0  As such, African immigrants are to be distingu...  \n",
       "1  A glacier cave is a cave formed within the ice...  \n",
       "2  Pumps operate by some mechanism (typically rec...  \n",
       "3  Employing over 6,000, BMC is often credited wi...  \n",
       "4  For 2011, the company recorded an annual reven...  \n",
       "5     This tablespoon has a capacity of about 15 mL.  \n",
       "6  In the USA one tablespoon (measurement unit) i...  \n",
       "7  In Australia one tablespoon (measurement unit)...  \n",
       "8  The series also originated much tie-in merchan...  \n",
       "9  A rocket engine, or simply \"rocket\", is a jet ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki_df = pd.read_csv('WikiQACorpus/WikiQA.tsv',sep = '\\t')\n",
    "\n",
    "flitered_df = Wiki_df[Wiki_df['Label'] == 1] \n",
    "flitered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "flitered_df.drop(columns = ['QuestionID'], inplace = True)\n",
    "flitered_df.drop(columns = ['DocumentID'], inplace = True)\n",
    "flitered_df.drop(columns = ['DocumentTitle'], inplace = True)\n",
    "flitered_df.drop(columns = ['SentenceID'], inplace = True)\n",
    "flitered_df.drop(columns = ['Label'], inplace = True)\n",
    "\n",
    "flitered_df.to_csv('WikiQACorpus/flitered_WikiQA', sep='\\t')\n",
    "flitered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06718d21-875a-4063-91be-a7f1118a44b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 1470 sentence pairs\n",
      "Trimmed to 1470 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 2464\n",
      "[['how african americans were immigrated to the us', 'as such african immigrants are to be distinguished from african american people the latter of whom are descendants of mostly west and central africans who were involuntarily brought to the united states by means of the historic atlantic slave trade .'], ['how are glacier caves formed ?', 'a glacier cave is a cave formed within the ice of a glacier .'], ['how a water pump works', 'pumps operate by some mechanism typically reciprocating or rotary and consume energy to perform mechanical work by moving the fluid .'], ['how big is bmc software in houston tx', 'employing over bmc is often credited with pioneering the bsm concept as a way to help better align it operations with business needs .'], ['how big is bmc software in houston tx', 'for the company recorded an annual revenue of . billion making it the largest software company in terms of revenue for that year .'], ['how much is tablespoon of water', 'this tablespoon has a capacity of about ml .'], ['how much is tablespoon of water', 'in the usa one tablespoon measurement unit is approximately ml the capacity of an actual tablespoon dining utensil ranges from ml to ml .'], ['how much is tablespoon of water', 'in australia one tablespoon measurement unit is ml .'], ['how much are the harry potter movies worth', 'the series also originated much tie in merchandise making the harry potter brand worth in excess of billion .'], ['how a rocket engine works', 'a rocket engine or simply rocket is a jet engine that uses only stored propellant mass for forming its high speed propulsive jet .']]\n",
      "170309\n"
     ]
    }
   ],
   "source": [
    "# Microsoft Research WikiQA Corpus\n",
    "corpus2 = 'WikiQACorpus'\n",
    "corpus2_name = corpus2\n",
    "datafile2 = os.path.join(corpus2, \"flitered_WikiQA\")\n",
    "voc2, pairs2 = loadPrepareData(corpus2, corpus2_name, datafile2, save_dir)\n",
    "\n",
    "# merge the voc togther \n",
    "voc.word2index.update(voc2.word2index)\n",
    "\n",
    "# reformat the new pair before merging\n",
    "pairs2 = pairs2[1:]\n",
    "pairs2 = [ lst[1:] for lst in pairs2 ] \n",
    "print(pairs2[:10])\n",
    "\n",
    "# merge the pairs togther \n",
    "pairs += pairs2\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6317b-d5bc-42f9-bb60-d9a87a371a32",
   "metadata": {},
   "source": [
    "### Twitter Conversational Corpus Preprocessing & Merging the vocabulary and the list of pairs\n",
    "    Modified the pre-existed function and add codes that written by ourseleves.\n",
    "    Reference: https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188989f9-904c-4980-9c87-79538ad8d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3 = 'TwitterCorpus'\n",
    "corpus3_name = corpus3\n",
    "datafile3 = os.path.join(corpus3, \"chat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd7e561-aec3-4102-9e96-fcfe0571f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLines(file, n=5):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "        \n",
    "def loadPrepareTwitterData(corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "        \n",
    "def extractSentencePairs_T(fileName):\n",
    "    qa_pairs = []\n",
    "    inputLine=''\n",
    "    targetLine=''\n",
    "    check=False\n",
    "    with open(fileName, 'r', encoding='UTF-8') as f:\n",
    "        for count,line in enumerate(f):\n",
    "            count += 1\n",
    "            if (count % 2) == 0:\n",
    "                targetLine = emoji.replace_emoji(line, replace='')\n",
    "                targetLine = targetLine.strip()\n",
    "                check = True\n",
    "            else:\n",
    "                inputLine = emoji.replace_emoji(line, replace='')\n",
    "                inputLine = inputLine.strip()\n",
    "                check = False\n",
    "            \n",
    "            if check:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "\n",
    "        \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d9fafeb-65e6-4237-b3a1-949fb6c0a6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"yeah i'm preparing myself to drop a lot on this man, but definitely need something reliable\\tyeah dude i would definitely consider a daniel defence super reliable and they are just bad ass\\r\\n\"\n",
      "b\"i'm about to meet my mans ex friend with benefit, tune in next week to see if i have to put hands on\\ti'm dead not looking forward to this\\r\\n\"\n",
      "b\"shouldn't the supporter's natural answer to 's hashtag be ?\\tor just insert itl to make .\\r\\n\"\n",
      "b'you want to turn twitter followers into blog readers.\\thow do you do this?\\r\\n'\n",
      "b\"besides if trump say his condolences it won't sound genuine, ex: (dwayne wade cousin) it will sound all political and petty\\tyea you right. but we do live in a world where republicans will harass obama about a birth certificate but won't say\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open('TwitterCorpus/reformatted_chat.txt', 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs_T(datafile3):\n",
    "#         if '.' in pair[0]:\n",
    "#             pair[0] = pair[0].replace('.', '')\n",
    "#         if '.' in pair[1]:\n",
    "#             pair[1] = pair[1].replace('.', '')\n",
    "        writer.writerow(pair)\n",
    "    \n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines('TwitterCorpus/reformatted_chat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e714293b-3668-40a0-9d4f-51896ae87196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 377265 sentence pairs\n",
      "Trimmed to 307064 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 111038\n",
      "\n",
      "pairs:\n",
      "['yeah i m preparing myself to drop a lot on this man but definitely need something reliable', 'yeah dude i would definitely consider a daniel defence super reliable and they are just bad ass']\n",
      "['i m about to meet my mans ex friend with benefit tune in next week to see if i have to put hands on', 'i m dead not looking forward to this']\n",
      "['shouldn t the supporter s natural answer to s hashtag be ?', 'or just insert itl to make .']\n",
      "['you want to turn twitter followers into blog readers .', 'how do you do this ?']\n",
      "['besides if trump say his condolences it won t sound genuine ex dwayne wade cousin it will sound all political and petty', 'yea you right . but we do live in a world where republicans will harass obama about a birth certificate but won t say']\n",
      "['well i finally finished watching all the episodes of breaking the magician s code magic s biggest secrets finally revealed on netflix .', 'now you are a walking spoiler . . .']\n",
      "['then again some sf hipsters would rather get crushed by a rack of fixie bikes in an earthquake than have to move out .', 'in seriousness if the next . happens in my lifetime i really hope i m not walking around downtown sf when it hits .']\n",
      "['does the dog also have polio', 'i think he is an old pupper ian he just wants some pizza tbh']\n",
      "['accelerate operation in . best response for any action pakistan and army .', 'while accelerating corruption schemes before next topi wala gets the charge']\n",
      "['bre takin shots', 'just standing up for my friends yo i figured i d take it for them']\n"
     ]
    }
   ],
   "source": [
    "voc3, pairs3 = loadPrepareTwitterData(corpus3, 'TwitterCorpus/reformatted_chat.txt')\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair3 in pairs3[:10]:\n",
    "    print(pair3)\n",
    "# print(voc3.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b3b341-5432-4f93-b526-641b1b740db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477373\n"
     ]
    }
   ],
   "source": [
    "# merge the voc togther \n",
    "voc.word2index.update(voc3.word2index)\n",
    "\n",
    "# merge the pairs togther \n",
    "pairs += pairs3\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897ef3e-dea9-40e2-908e-21f40c2bdc43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eliminating most of the marks from really short answers\n",
    "    Codes written by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c848a34f-209a-4e6a-868d-82a86e44ade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['they do to !', 'they do not !'], ['she okay ?', 'i hope so .'], ['wow', 'let s go .'], ['i m kidding . you know how sometimes you just become this persona ? and you don t know how to quit ?', 'no'], ['no', 'okay you re gonna need to learn how to lie .'], ['i figured you d get to the good stuff eventually .', 'what good stuff ?'], ['what good stuff ?', 'the real you .'], ['the real you .', 'like my fear of wearing pastels ?'], ['do you listen to this crap ?', 'what crap '], ['what crap ?', 'me . this endless . . .blonde babble . i m like boring myself .']]\n"
     ]
    }
   ],
   "source": [
    "for lst in pairs:\n",
    "    if len(lst[1].split()) <= 3:\n",
    "        lst[1] = lst[1].replace('.', '')\n",
    "        lst[1] = lst[1].replace('?', '')\n",
    "        lst[1] = lst[1].replace('!', '')\n",
    "print(pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b35bd-0f78-44c6-bcc9-287fc4276eb5",
   "metadata": {},
   "source": [
    "### Achieving faster convergence during training by trimming rarely used words out of our vocabulary\n",
    "    Modified the pre-existed function and add codes that written by ourseleves.\n",
    "    Reference:\n",
    "        https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aec309b-e673-42e4-9173-bb539f9ba045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 14285 / 120815 = 0.1182\n",
      "Trimmed from 477373 pairs to 187731, 0.3933 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5   # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58626641-93c0-4381-92fe-f96260ad32d0",
   "metadata": {},
   "source": [
    "## Transform to numerical torch tensors as inputs\n",
    "    Reference:\n",
    "        https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c74a43-f5aa-451d-b78a-30d6cb3ca106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  137,  1086,   336,   155,  1765],\n",
      "        [  110,  4090,    42,    39,  5860],\n",
      "        [   84,  4230,    14,     3,  4989],\n",
      "        [ 4424,   288,   154,   413,    14],\n",
      "        [12848,  3575,    17,   317,     2],\n",
      "        [   14,    66, 10416,    10,     0],\n",
      "        [   16,   287,    14,     2,     0],\n",
      "        [   17,    14,     2,     0,     0],\n",
      "        [  461,    14,     0,     0,     0],\n",
      "        [   28,    14,     0,     0,     0],\n",
      "        [  291,     2,     0,     0,     0],\n",
      "        [  263,     0,     0,     0,     0],\n",
      "        [   14,     0,     0,     0,     0],\n",
      "        [    2,     0,     0,     0,     0]])\n",
      "lengths: tensor([14, 11,  8,  7,  5])\n",
      "target_variable: tensor([[   41,    32,    23,    41,   123],\n",
      "        [  337,    14,   179,  1446,    41],\n",
      "        [  137,   211,     8,  2571,  1438],\n",
      "        [   14,   288,   555,    14,  4041],\n",
      "        [  137,  1408,    27,     2,   889],\n",
      "        [   17,     5,    10,     0,    21],\n",
      "        [  251,    54,    27,     0,     7],\n",
      "        [    5,    14,   439,     0,     5],\n",
      "        [   89,     4, 10163,     0,   602],\n",
      "        [   27,   103,     5,     0,  6306],\n",
      "        [ 2319,   835,  3992,     0, 10339],\n",
      "        [   14,  1595,    91,     0,    10],\n",
      "        [    2,   418,   122,     0,     2],\n",
      "        [    0,    10,   629,     0,     0],\n",
      "        [    0,     2,    14,     0,     0],\n",
      "        [    0,     0,     2,     0,     0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [False,  True,  True, False, False],\n",
      "        [False,  True,  True, False, False],\n",
      "        [False, False,  True, False, False]])\n",
      "max_target_len: 16\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93d034-23cd-400e-85bb-69097aba86b6",
   "metadata": {},
   "source": [
    "## Defining Seq2Seq model, training, and chatbot conversation\n",
    "    Modified the pre-existed function and add codes that written by ourseleves.\n",
    "    Reference:\n",
    "        https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b0e5546-e57b-44a6-9cdc-30e633cf71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3657a9f5-a721-4944-8902-88dc4da9f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8be3e95-2aca-4dbb-8a46-b9fe6b70b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c20e37-1481-4f72-bfa8-f992137349b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b85f967-af20-43c3-80dd-c808fb75f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb103e55-d5bb-48f5-a555-a48a4dac3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a978b68c-952f-42f6-be6a-9531a5eb0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9ee7cf-f68d-44fd-9557-4cba2bd74c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edea8fed-30ae-47ac-ad63-bc2386918f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "# attn_model = 'general'\n",
    "# attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 2000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f986516-916b-440f-abee-b1c2e357b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1000; Percent complete: 10.0%; Average loss: 4.9394\n",
      "Iteration: 2000; Percent complete: 20.0%; Average loss: 4.4073\n",
      "Iteration: 3000; Percent complete: 30.0%; Average loss: 4.2613\n",
      "Iteration: 4000; Percent complete: 40.0%; Average loss: 4.1673\n",
      "Iteration: 5000; Percent complete: 50.0%; Average loss: 4.1037\n",
      "Iteration: 6000; Percent complete: 60.0%; Average loss: 4.0503\n",
      "Iteration: 7000; Percent complete: 70.0%; Average loss: 3.9879\n",
      "Iteration: 8000; Percent complete: 80.0%; Average loss: 3.9488\n",
      "Iteration: 9000; Percent complete: 90.0%; Average loss: 3.9103\n",
      "Iteration: 10000; Percent complete: 100.0%; Average loss: 3.8614\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 10000\n",
    "print_every = 1000\n",
    "save_every = 2000\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f5a2d-d31b-4560-b9f4-024266a2211c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation\n",
    "    modified the pre-existed function and add codes that written by ourseleves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7423fbae-06af-4f2c-a113-90fd10550975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5eaca5f-83b9-4238-b603-847c6f146d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    testerNum = input('Type your tester number: ')\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "            \n",
    "    # Evaluating by user studies  \n",
    "    print('\\nCommunication Competency')\n",
    "    print('On a scale of 0 to 4 (it could be real numbers)')\n",
    "    print('Failed - Unsatisfied - Satisfied - Good - Excellent')\n",
    "    \n",
    "    E_score = float(input('Would you prefer to talk to the chatbot for a long conversation? '))\n",
    "    I_score = float(input('How interesting is the content of the chatbot? '))\n",
    "    H_score = float(input('Does the chatbot sound human? '))\n",
    "    \n",
    "    print(f'Engagingness: {E_score}')\n",
    "    print(f'Interestingness: {I_score}') \n",
    "    print(f'Humanness: {H_score}')\n",
    "    print('Thanks for your evaluation!')\n",
    "    \n",
    "    return [E_score, I_score, H_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "126745cc-7263-41e2-9cae-c8b141709e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_scores = list()\n",
    "I_scores = list()\n",
    "H_scores = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aebee23e-f3f5-433b-88ac-b0f0d3a9474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  1\n",
      ">  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hi \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m fine . is a great wooden . is a great deal . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What do you mean by saying wooden and deal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the man who s not here . of the man who s dying . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you the man dying?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Ok, good. What is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of my favorite name . of the gold . is my favorite name . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You like gold?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yeah \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Why you like gold?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the girls . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  girls?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yes \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what about girls?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the gold . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Fine, goodbye.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do not worry about it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not sure if you don t do it . of you . of you ! !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  0.9\n",
      "How interesting is the content of the chatbot?  2.2\n",
      "Does the chatbot sound human?  1.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 0.9\n",
      "Interestingness: 2.2\n",
      "Humanness: 1.8\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 1: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9133219-0a30-43a8-be2d-ed0e59a62d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  2\n",
      ">  Who is the president?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is the best thing . is the best thing . is the best thing . is the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What year is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the gold . is a good thing . is a good idea . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I am tired. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you my friend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Can we be friends?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: we re not going to be here . we re going to work . we re going to work . of us\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like flowers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I think you are cute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . i m sorry . are you ? ? ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  1.7\n",
      "How interesting is the content of the chatbot?  1\n",
      "Does the chatbot sound human?  0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 1.7\n",
      "Interestingness: 1.0\n",
      "Humanness: 0.3\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 2: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51ffb7ef-59e9-40e4-9b36-768abcf3ec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  3\n",
      ">  Hello.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hello \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m fine . is a great wooden . is a great deal . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like to chat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not going to do it . you re going to have a brain . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you have a brain?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you real?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not sure . of us . of us . of us . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I am real. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is good . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do not be sorry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of you . of you . of you . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I know you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i know \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you a computer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . . i m sorry . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are cool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Yes you are.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . of my life . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are useful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like to talk?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is your job?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . is the best thing . is the best thing . is the best thing .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you tired?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are bored?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yes \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Will you rest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  2.5\n",
      "How interesting is the content of the chatbot?  2.7\n",
      "Does the chatbot sound human?  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 2.5\n",
      "Interestingness: 2.7\n",
      "Humanness: 2.0\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 3: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0931380b-b0a1-47fd-ad6f-a7233e7bc48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  4\n",
      ">  Hi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hi \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like food.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . is the best thing . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  It is night time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is the best thing . is the best thing . is the best thing . is the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . of my life . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  When will you end?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . of us . of us . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are slow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are boring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to waste . are you ? ? ? ? ? ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  No.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not going to do anything . of you . is your wife . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I have to go.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i ll go . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Will you live?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . of the people who do . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you sleep?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Good bye.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: good morning \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  3.6\n",
      "How interesting is the content of the chatbot?  3\n",
      "Does the chatbot sound human?  2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 3.6\n",
      "Interestingness: 3.0\n",
      "Humanness: 2.2\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 4: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51aa622b-86c6-457c-b6e8-cf897a215f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  5\n",
      ">  Hello.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hello \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like music.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like music?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the people who do . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Is it dark?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: it s not the only one . is it ? ? ? ? ? ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Where are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going anywhere . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Will you go to sleep?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i ll go . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are quiet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you simple?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . of my life . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not going to work . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like to do work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not going to do it . you re going to work . you re going to work . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I will do my job.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i ll do it . i ll do it . i ll do the show . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Show me your job.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . i m not going to be a fireman . i m gonna do . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like fireman.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you don t have to do it . you re not going to do it . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Shut down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Be quiet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to see you . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I do not care.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not going to do it . of you . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  2.5\n",
      "How interesting is the content of the chatbot?  1.9\n",
      "Does the chatbot sound human?  1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 2.5\n",
      "Interestingness: 1.9\n",
      "Humanness: 1.1\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 5: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9328665c-e948-4084-8883-438a7110ad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  6\n",
      ">  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m fine . is a great wooden . is a great deal . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of you . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you real?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not sure . of us . of us . of us . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I made you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the business . i know . of the world . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like the world?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like arts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Global warming is scary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Am I your friend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you use twitter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Encountered unknown word.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you smart?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . of my favorites . of us . of us . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  .3\n",
      "How interesting is the content of the chatbot?  0.2\n",
      "Does the chatbot sound human?  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 0.3\n",
      "Interestingness: 0.2\n",
      "Humanness: 0.1\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 6: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1126fc0-d8d3-45ae-9cad-c2dcd3a39dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  7\n",
      ">  I am your friend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Give me a report.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of my life . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of my life . of my life . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  When will you work?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . of the night . of the night . of the night .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I think you are useful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are not useful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you fast?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to see you . of you . of us . of us . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Can you see the world?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . of the man . of the man . of the man . of the man .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Who is in charge?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . of the season . of the season . of the season .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like winter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you like radio?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you know Lady Gaga?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Encountered unknown word.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like music and art.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Art is good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . is a good friend . is a good friend . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Good bye bot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Encountered unknown word.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Good bye.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: good morning \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  0\n",
      "How interesting is the content of the chatbot?  0.5\n",
      "Does the chatbot sound human?  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 0.0\n",
      "Interestingness: 0.5\n",
      "Humanness: 0.0\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 7: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "039cb556-8db5-42c4-adde-6d93489936ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  8\n",
      ">  I hate you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . i m sorry . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you know me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I like movies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not . . you re not going to be a good friend . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I will be a good friend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i ll be there . are you ? ? ? ? ? ? ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I will be here for you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i ll be here for you . i ll do the proper thing . i do . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Will you marry me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . of us . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I do not want to study.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you re not . is very dangerous . is very dangerous . is very dangerous . is very dangerous .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Can you work today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . of the best thing . of the world . of the best . of the craft .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  When will you sleep?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . of us . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I think you are scared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . are you ? ? ? ? ? ? ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are you scared?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I am.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . is a good friend . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You are good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . of you are very very good . are you ? ? ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  2\n",
      "How interesting is the content of the chatbot?  2.6\n",
      "Does the chatbot sound human?  1.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 2.0\n",
      "Interestingness: 2.6\n",
      "Humanness: 1.8\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 8: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cab1578-4c1e-4d07-8cfb-76eb9f53c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  9\n",
      ">  Hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hey you re not going to be a fireman . of us . of us . of us . !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  why you say that?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . i m not . . . i m sorry . . . i m sorry . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  ok. Do you like the earth?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . of the night . of the night . is a good friend\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what do you know about the ocean?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the man s name . of the man s name . i know . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What name is the best?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the gold . of the gold . of the gold . of the gold .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what gold?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . of us . of us . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  do you fear of something?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: no \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what you going to do tomorrow?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to work . i m going to go . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  You hate working?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . i m sorry . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do not be sorry!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not sure it s not true . of the people are in the middle of the season . of the world\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  people in the middle of the season?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the season . of the season . of the season . of the season .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  0.8\n",
      "How interesting is the content of the chatbot?  1.8\n",
      "Does the chatbot sound human?  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 0.8\n",
      "Interestingness: 1.8\n",
      "Humanness: 0.5\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 9: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "791506ce-43c7-41cf-9e3c-47fb1fcab675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your tester number:  10\n",
      ">  Good afternoon!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: thanks for coming ! ! ! ! ! ! ! ! ! ! !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Is this your place?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the night . is the best thing . is the best thing . is the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  where do you live?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of the world . of the world . of the world . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  How are you feel?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m fine . is a good one . is a good one . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Could you talk a little more?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m not going to waste . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  waste waht?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Encountered unknown word.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  waste what?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i don t know . of us . of us . ! ! ! ! ! !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what is your favorite color?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i m sorry . i m sorry . i m sorry . is a good friend . is a big problem .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Communication Competency\n",
      "On a scale of 0 to 4 (it could be real numbers)\n",
      "Failed - Unsatisfied - Satisfied - Good - Excellent\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you prefer to talk to the chatbot for a long conversation?  0.8\n",
      "How interesting is the content of the chatbot?  1.1\n",
      "Does the chatbot sound human?  0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: 0.8\n",
      "Interestingness: 1.1\n",
      "Humanness: 0.2\n",
      "Thanks for your evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Volunteer 10: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b07ac2-31b0-4e78-a704-2743cb520b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagingness: [0.9, 1.7, 2.5, 3.6, 2.5, 0.3, 0.0, 2.0, 0.8, 0.8]\n",
      "Interestingness: [2.2, 1.0, 2.7, 3.0, 1.9, 0.2, 0.5, 2.6, 1.8, 1.1]\n",
      "Humanness: [1.8, 0.3, 2.0, 2.2, 1.1, 0.1, 0.0, 1.8, 0.5, 0.2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Evaluation_dim = ['Engagingness', 'Interestingness', 'Humanness']\n",
    "print(f'Engagingness: {E_scores}\\nInterestingness: {I_scores}\\nHumanness: {H_scores}')\n",
    "\n",
    "avgE = sum(E_scores) / len(E_scores)\n",
    "avgI = sum(I_scores) / len(I_scores)\n",
    "avgH = sum(H_scores) / len(H_scores)\n",
    "\n",
    "Avg_scores = [avgE, avgI, avgH]\n",
    "\n",
    "plt.bar(Evaluation_dim, Avg_scores)\n",
    "plt.title('Evaluation results from our chatbot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ce75bf6-e376-417f-8706-00f68d5f57c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collected scores from the original chatbot\n",
    "E_scoresOG = [1.2, 0.5, 0.8, 1.3, 2.0, 2.2, 1.5, 0.8, 0.9, 2.0]\n",
    "I_scoresOG = [2.5, 1.6, 2.0, 1.1, 2.5, 2.5, 1.5, 1.5, 1.4, 2.1]\n",
    "H_scoresOG = [1.5, 0.8, 1.4, 1.0, 1.1, 1.5, 0.8, 0.5, 0.5, 1.6]\n",
    "\n",
    "Evaluation_dim = ['Original Chatbot Engagingness', \n",
    "                  'Our Chatbot Engagingness',\n",
    "                  'Original Chatbot Interestingness', \n",
    "                  'Our Chatbot Interestingness',\n",
    "                  'Original Chatbot Humanness',\n",
    "                  'Our Chatbot Humanness']\n",
    "\n",
    "OGavgE = sum(E_scoresOG) / len(E_scoresOG)\n",
    "OGavgI = sum(I_scoresOG) / len(I_scoresOG)\n",
    "OGavgH = sum(H_scoresOG) / len(H_scoresOG)\n",
    "\n",
    "Avg_scores = [OGavgE, avgE, OGavgI, avgI, OGavgH, avgH]\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "plt.bar(Evaluation_dim, Avg_scores)\n",
    "plt.title('Comparison of Evaluation results')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89a645-ff30-43ad-a1a8-6227cfa25372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb99559-74df-4a72-9aaa-4b6508ca2e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0311e6-31e8-47e7-bc35-d5cf063a2a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
