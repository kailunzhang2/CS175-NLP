{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9318529a",
   "metadata": {},
   "source": [
    "### Twitter Conversational Corpus Preprocessing & Merging the vocabulary and the list of pairs\n",
    "    Modified the pre-existed function and add codes that written by ourseleves.\n",
    "    Reference: https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3_name = 'TwitterCorpus'\n",
    "corpus3 = os.path.join(\"data\", corpus3_name)\n",
    "twitter = os.path.join(corpus3, \"chat.txt\")\n",
    "datafile3 = os.path.join(corpus3, \"reformatted_chat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd23907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLines(file, n=5):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "        \n",
    "def extractSentencePairs_T(fileName):\n",
    "    qa_pairs = []\n",
    "    inputLine=''\n",
    "    targetLine=''\n",
    "    check=False\n",
    "    with open(fileName, 'r', encoding='UTF-8') as f:\n",
    "        for count,line in enumerate(f):\n",
    "            count += 1\n",
    "            if (count % 2) == 0:\n",
    "                targetLine = emoji.replace_emoji(line, replace='')\n",
    "                targetLine = targetLine.strip()\n",
    "                check = True\n",
    "            else:\n",
    "                inputLine = emoji.replace_emoji(line, replace='')\n",
    "                inputLine = inputLine.strip()\n",
    "                check = False\n",
    "            \n",
    "            if check:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "\n",
    "        \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea08283",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile3, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs_T(twitter):\n",
    "        if '.' in pair[0]:\n",
    "            pair[0] = pair[0].replace('.', '')\n",
    "        if '.' in pair[1]:\n",
    "            pair[1] = pair[1].replace('.', '')\n",
    "        writer.writerow(pair)\n",
    "    \n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe829152",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc3, pairs3 = loadPrepareData(corpus3, corpus3_name, datafile3, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair3 in pairs3[:10]:\n",
    "    print(pair3)\n",
    "# print(voc3.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the voc togther \n",
    "voc.word2index.update(voc3.word2index)\n",
    "\n",
    "# merge the pairs togther \n",
    "pairs += pairs3\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('voc.pickle', 'wb') as v:\n",
    "    pickle.dump(voc, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
