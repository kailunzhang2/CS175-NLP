{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac241ea",
   "metadata": {},
   "source": [
    "## Microsoft Research WikiQA Corpus Preprocessing & Merging with the list of pairs\n",
    "    Codes written by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59929651",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wiki_df = pd.read_csv('WikiQACorpus/WikiQA.tsv',sep = '\\t')\n",
    "\n",
    "flitered_df = Wiki_df[Wiki_df['Label'] == 1] \n",
    "flitered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "flitered_df.drop(columns = ['QuestionID'], inplace = True)\n",
    "flitered_df.drop(columns = ['DocumentID'], inplace = True)\n",
    "flitered_df.drop(columns = ['DocumentTitle'], inplace = True)\n",
    "flitered_df.drop(columns = ['SentenceID'], inplace = True)\n",
    "flitered_df.drop(columns = ['Label'], inplace = True)\n",
    "\n",
    "flitered_df.to_csv('WikiQACorpus/flitered_WikiQA', sep='\\t')\n",
    "flitered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89441efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Research WikiQA Corpus\n",
    "corpus2 = 'WikiQACorpus'\n",
    "corpus2_name = corpus2\n",
    "datafile2 = os.path.join(corpus2, \"flitered_WikiQA\")\n",
    "voc2, pairs2 = loadPrepareData(corpus2, corpus2_name, datafile2, save_dir)\n",
    "\n",
    "# merge the voc togther \n",
    "voc.word2index.update(voc2.word2index)\n",
    "\n",
    "# reformat the new pair before merging\n",
    "pairs2 = pairs2[1:]\n",
    "pairs2 = [ lst[1:] for lst in pairs2 ] \n",
    "print(pairs2[:10])\n",
    "\n",
    "# merge the pairs togther \n",
    "pairs += pairs2\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cbbb92",
   "metadata": {},
   "source": [
    "## Eliminating most of the marks from really short answers\n",
    "    Codes written by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69413b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst in pairs:\n",
    "    if len(lst[1].split()) <= 3:\n",
    "        lst[1] = lst[1].replace('.', '')\n",
    "        lst[1] = lst[1].replace('?', '')\n",
    "        lst[1] = lst[1].replace('!', '')\n",
    "print(pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad9349",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "    modified the pre-existed function and add codes that written by ourseleves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64277184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    testerNum = input('Type your tester number: ')\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "            \n",
    "    # Evaluating by user studies  \n",
    "    print('\\nCommunication Competency')\n",
    "    print('On a scale of 0 to 4 (it could be real numbers)')\n",
    "    print('Failed - Unsatisfied - Satisfied - Good - Excellent')\n",
    "    \n",
    "    E_score = float(input('Would you prefer to talk to the chatbot for a long conversation? '))\n",
    "    I_score = float(input('How interesting is the content of the chatbot? '))\n",
    "    H_score = float(input('Does the chatbot sound human? '))\n",
    "    \n",
    "    print(f'Engagingness: {E_score}')\n",
    "    print(f'Interestingness: {I_score}') \n",
    "    print(f'Humanness: {H_score}')\n",
    "    print('Thanks for your evaluation!')\n",
    "    \n",
    "    return [E_score, I_score, H_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c549f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_scores = list()\n",
    "I_scores = list()\n",
    "H_scores = list()\n",
    "# Volunteer 1: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])\n",
    "# Volunteer 2: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])\n",
    "# Volunteer 3: Begin chatting, type 'q' to quit conversation\n",
    "score_list = evaluateInput(encoder, decoder, searcher, voc)\n",
    "\n",
    "E_scores.append(score_list[0])\n",
    "I_scores.append(score_list[1])\n",
    "H_scores.append(score_list[2])\n",
    "# Volunteer user studies exmaples continue ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
